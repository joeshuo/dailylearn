{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a76bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始执行充电负荷数据批量加总任务 ---\n",
      "发现 14 个Excel文件，准备开始读取...\n",
      "  -> 正在读取文件: 十堰.xls\n",
      "  -> 正在读取文件: 咸宁.xls\n",
      "  -> 正在读取文件: 孝感.xls\n",
      "  -> 正在读取文件: 宜昌.xls\n",
      "  -> 正在读取文件: 恩施.xls\n",
      "  -> 正在读取文件: 武汉.xls\n",
      "  -> 正在读取文件: 神农架.xls\n",
      "  -> 正在读取文件: 荆州.xls\n",
      "  -> 正在读取文件: 荆门.xls\n",
      "  -> 正在读取文件: 襄阳.xls\n",
      "  -> 正在读取文件: 鄂州.xls\n",
      "  -> 正在读取文件: 随州.xls\n",
      "  -> 正在读取文件: 黄冈.xls\n",
      "  -> 正在读取文件: 黄石.xls\n",
      "\n",
      "所有文件读取完毕，正在合并数据...\n",
      "数据合并完成！\n",
      "正在进行数据清洗和类型转换...\n",
      "数据清洗完成！\n",
      "正在按天对所有地市的负荷进行加总...\n",
      "数据加总完成！\n",
      "\n",
      "正在将最终结果保存到: E:\\A智网\\分地市202508充电负荷数据\\湖北省充电负荷数据.xlsx\n",
      "\n",
      "--- 全部任务成功完成！ ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 配置层 (Configuration Layer)\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"集中管理所有文件路径和常量\"\"\"\n",
    "    # --- 【请修改】输入和输出路径 ---\n",
    "    # 输入文件夹：包含所有地市Excel文件的文件夹\n",
    "    INPUT_DIR = Path(r'E:\\A智网\\分地市202508充电负荷数据\\充电负荷数据')\n",
    "    \n",
    "    # 输出文件：最终汇总表的保存路径和文件名\n",
    "    OUTPUT_FILE = Path(r'E:\\A智网\\分地市202508充电负荷数据\\湖北省充电负荷数据.xlsx')\n",
    "\n",
    "    # --- 文件读取参数 ---\n",
    "    # 根据你的Excel文件格式，我们需要跳过前面的2行\n",
    "    ROWS_TO_SKIP = 2\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 主流程 (Main Workflow)\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    \"\"\"主执行函数，完成数据读取、聚合和保存\"\"\"\n",
    "    print(\"--- 开始执行充电负荷数据批量加总任务 ---\")\n",
    "\n",
    "    # 检查输入文件夹是否存在\n",
    "    if not Config.INPUT_DIR.exists():\n",
    "        print(f\"[致命错误] 输入文件夹不存在: {Config.INPUT_DIR}\")\n",
    "        return\n",
    "\n",
    "    # 1. 读取所有地市的Excel文件\n",
    "    all_city_dataframes = []\n",
    "    # 使用 .glob('*.xls*') 可以同时匹配 .xls 和 .xlsx 文件\n",
    "    excel_files = list(Config.INPUT_DIR.glob('*.xls*'))\n",
    "\n",
    "    if not excel_files:\n",
    "        print(f\"[致命错误] 在文件夹 {Config.INPUT_DIR} 中没有找到任何Excel文件。\")\n",
    "        return\n",
    "\n",
    "    print(f\"发现 {len(excel_files)} 个Excel文件，准备开始读取...\")\n",
    "\n",
    "    for file_path in excel_files:\n",
    "        print(f\"  -> 正在读取文件: {file_path.name}\")\n",
    "        try:\n",
    "            # 使用 skiprows 参数跳过文件顶部的标题和空行\n",
    "            df = pd.read_excel(file_path, skiprows=Config.ROWS_TO_SKIP)\n",
    "            \n",
    "            # 简单的有效性检查，确保DataFrame包含预期的数据\n",
    "            if '日期' in df.columns and len(df.columns) > 90:\n",
    "                all_city_dataframes.append(df)\n",
    "            else:\n",
    "                print(f\"    [警告] 文件 {file_path.name} 的格式似乎不正确，已跳过。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    [错误] 读取文件 {file_path.name} 时发生错误，已跳过。\")\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "    \n",
    "    if not all_city_dataframes:\n",
    "        print(\"\\n[处理中断] 未能成功读取任何有效数据，请检查上述错误日志。\")\n",
    "        return\n",
    "\n",
    "    # 2. 合并所有数据到一个大的DataFrame\n",
    "    print(\"\\n所有文件读取完毕，正在合并数据...\")\n",
    "    combined_df = pd.concat(all_city_dataframes, ignore_index=True)\n",
    "    print(\"数据合并完成！\")\n",
    "\n",
    "    # 3. 数据清洗与转换\n",
    "    print(\"正在进行数据清洗和类型转换...\")\n",
    "    \n",
    "    # a. 转换“日期”列为标准的日期格式\n",
    "    #    format='%Y%m%d' 告诉pandas如何解析像 20250801 这样的整数/字符串\n",
    "    combined_df['日期'] = pd.to_datetime(combined_df['日期'], format='%Y%m%d')\n",
    "\n",
    "    # b. 确定所有时间点列（从第4列到最后一列）\n",
    "    time_point_columns = combined_df.columns[3:]\n",
    "\n",
    "    # c. 将所有时间点列转换为数值类型，无法转换的将变成NaN\n",
    "    #    然后用0填充所有NaN值，确保加总时不会出错\n",
    "    combined_df[time_point_columns] = combined_df[time_point_columns].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    print(\"数据清洗完成！\")\n",
    "\n",
    "    # 4. 核心聚合操作：按日期分组，并对所有时间点列求和\n",
    "    print(\"正在按天对所有地市的负荷进行加总...\")\n",
    "    # groupby('日期') 会将所有相同日期的数据行分到一组\n",
    "    # .sum() 会自动对该组内所有数值列（即我们的96个时间点）进行求和\n",
    "    aggregated_df = combined_df.groupby('日期')[time_point_columns].sum()\n",
    "\n",
    "    # 将作为索引的“日期”列重新变回普通列\n",
    "    aggregated_df = aggregated_df.reset_index()\n",
    "    print(\"数据加总完成！\")\n",
    "\n",
    "    # 5. 保存结果到新的Excel文件\n",
    "    print(f\"\\n正在将最终结果保存到: {Config.OUTPUT_FILE}\")\n",
    "    try:\n",
    "        # 确保输出目录存在\n",
    "        Config.OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # to_excel 保存数据\n",
    "        aggregated_df.to_excel(Config.OUTPUT_FILE, index=False, engine='openpyxl')\n",
    "        \n",
    "        print(\"\\n--- 全部任务成功完成！ ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"[致命错误] 保存文件时发生错误。\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dianli",
   "language": "python",
   "name": "dianli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
